# coding=utf-8
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

# Single Source Shortest Path

# Please refer to the sssp.sql_in file for the documentation

"""
@file sssp.py_in

@namespace graph
"""

import plpy
from graph_utils import *
from utilities.control import MinWarning
from utilities.utilities import _assert
from utilities.utilities import extract_keyvalue_params
from utilities.utilities import unique_string
from utilities.utilities import _string_to_array
from utilities.utilities import split_quoted_delimited_str
from utilities.validate_args import get_cols
from utilities.validate_args import unquote_ident
from utilities.validate_args import table_exists
from utilities.validate_args import columns_exist_in_table
from utilities.validate_args import table_is_empty
from utilities.validate_args import get_cols_and_types

m4_changequote(`<!', `!>')


def _check_groups(tbl1, tbl2, grp_list):

	"""
	Helper function for joining tables with groups.
	Args:
		@param tbl1       Name of the first table
		@param tbl2       Name of the second table
		@param grp_list   The list of grouping columns
	"""

	sql = []
	for i in grp_list:
		sql.append(" "+tbl1+"."+i+" = "+tbl2+"."+i+" ")
	return " AND ".join(sql)

def _grp_from_table(tbl1, grp_list):

	"""
	Helper function for selecting grouping columns of a table
	Args:
		@param tbl        Name of the table
		@param grp_list   The list of grouping columns
	"""

	sql = []
	for i in grp_list:
		sql.append(" "+tbl+"."+i+" ")
	return " , ".join(sql)

def graph_sssp(schema_madlib, vertex_table, vertex_id, edge_table,
		edge_args, source_vertex, out_table, grouping_cols, **kwargs):

	"""
    Single source shortest path function for graphs using the Bellman-Ford
    algorhtm [1].
    Args:
        @param vertex_table     Name of the table that contains the vertex data.
        @param vertex_id        Name of the column containing the vertex ids.
        @param edge_table       Name of the table that contains the edge data.
        @param edge_args        A comma-delimited string containing multiple
        						named arguments of the form "name=value".
        @param source_vertex    The source vertex id for the algorithm to start.
        @param out_table   	    Name of the table to store the result of SSSP.
        @param grouping_cols   	The list of grouping columns.

    [1] https://en.wikipedia.org/wiki/Bellman-Ford_algorithm
    """

	with MinWarning("warning"):

		INT_MAX = 2147483647
		EPSILON = 0.000001

		message = unique_string(desp='message')

		oldupdate = unique_string(desp='oldupdate')
		newupdate = unique_string(desp='newupdate')

		params_types = {'src': str, 'dest': str, 'weight': str}
		default_args = {'src': 'src', 'dest': 'dest', 'weight': 'weight'}
		edge_params = extract_keyvalue_params(edge_args,
                                            params_types,
                                            default_args)

		# Prepare the input for recording in the summary table
		if vertex_id is None:
			v_st= "NULL"
			vertex_id = "id"
		else:
			v_st = vertex_id
		if edge_args is None:
			e_st = "NULL"
		else:
			e_st = edge_args
		if grouping_cols is None:
			g_st = "NULL"
		else:
			g_st = grouping_cols

		src = edge_params["src"]
		dest = edge_params["dest"]
		weight = edge_params["weight"]

		distribution = m4_ifdef(<!__POSTGRESQL__!>, <!''!>,
			<!"DISTRIBUTED BY ({0})".format(vertex_id)!>)
		local_distribution = m4_ifdef(<!__POSTGRESQL__!>, <!''!>,
			<!"DISTRIBUTED BY (id)"!>)

		is_hawq = m4_ifdef(<!__HAWQ__!>, <!True!>, <!False!>)
		validate_sssp(vertex_table, vertex_id, edge_table,
			edge_params, source_vertex, out_table)

		plpy.execute(" DROP TABLE IF EXISTS {0},{1},{2}".format(
			message,oldupdate,newupdate))

		# Initialize grouping related variables
		comma_grp = ""
		comma_grp_e = ""
		comma_grp_m = ""
		grp_comma = ""
		checkg_oo = ""
		checkg_eo = ""
		checkg_ex = ""
		checkg_om = ""
		group_by = ""

		if grouping_cols is not None:
			glist = split_quoted_delimited_str(grouping_cols)
			comma_grp = " , " + grouping_cols
			group_by = " , " + _grp_from_table(edge_table,glist)
			comma_grp_e = " , " + _grp_from_table(edge_table,glist)
			comma_grp_m = " , " + _grp_from_table("message",glist)
			grp_comma = grouping_cols + " , "

			checkg_oo_sub = _check_groups(out_table,"oldupdate",glist)
			checkg_oo = " AND " + checkg_oo_sub
			checkg_eo = " AND " + _check_groups(edge_table,"oldupdate",glist)
			checkg_ex = " AND " + _check_groups(edge_table,"x",glist)
			checkg_om = " AND " + _check_groups("out_table","message",glist)


		# We keep a table of every vertex, the minimum cost to that destination
		# seen so far and the parent to this vertex in the associated shortest
		# path. This table will be updated throughtout the execution.
		plpy.execute(
			""" CREATE TABLE {out_table} AS ( SELECT
					{grp_comma} {src} AS {vertex_id}, {weight},
					{src} AS parent FROM {edge_table} LIMIT 0)
				{local_distribution} """.format(**locals()))

		# We keep a summary table to keep track of the parameters used for this
		# SSSP run. This table is used in the path finding function to eliminate
		# the need for repetition.
		plpy.execute( """ CREATE TABLE {out_table}_summary  (
			vertex_table            TEXT,
			vertex_id               TEXT,
			edge_table              TEXT,
			edge_args               TEXT,
			source_vertex           TEXT,
			out_table               TEXT,
			grouping_cols           TEXT)
			""".format(**locals()))
		plpy.execute( """ INSERT INTO {out_table}_summary VALUES
			('{vertex_table}', '{v_st}', '{edge_table}', '{e_st}',
			'{source_vertex}', '{out_table}', '{g_st}')
			""".format(**locals()))

		# We keep 2 update tables and alternate them during the execution.
		# This is necessary since we need to know which vertices are updated in
		# the previous iteration to calculate the next set of updates.
		plpy.execute(
			""" CREATE TEMP TABLE {oldupdate} AS ( SELECT
					{src} AS id, {weight},
					{src} AS parent {comma_grp} FROM {edge_table} LIMIT 0)
				{local_distribution}
				""".format(**locals()))
		plpy.execute(
			""" CREATE TEMP TABLE {newupdate} AS ( SELECT
					{src} AS id, {weight},
					{src} AS parent {comma_grp} FROM {edge_table} LIMIT 0)
				{local_distribution}
				""".format(**locals()))

		# Since HAWQ does not allow us to update, we create a new table and
		# rename at every iteration
		if is_hawq:
			temp_table = unique_string(desp='temp')
			sql =""" CREATE TABLE {temp_table} AS ( SELECT * FROM {out_table} )
				{distribution} """
			plpy.execute(sql.format(**locals()))

		# GPDB and HAWQ have distributed by clauses to help them with indexing.
		# For Postgres we add the indices manually.
		sql_index = m4_ifdef(<!__POSTGRESQL__!>,
			<!""" CREATE INDEX ON {out_table} ({vertex_id});
				CREATE INDEX ON {oldupdate} (id);
				CREATE INDEX ON {newupdate} (id);
			""".format(**locals())!>,
			<!''!>)
		plpy.execute(sql_index)

		# The initialization step is quite different when grouping is involved
		# since not every group (subgraph) will have the same set of vertices

		# Example:
		# Assume there are two grouping columns g1 and g2
		# g1 values are 0 or 1. g2 values are 5 or 6
		if grouping_cols is not None:

			# Collate the groups into a single column (string)
			gsql = "::text || ',' || ".join(glist)
			gsql = gsql + "::text "

			# Find every distinct group
			# Example: This will give us (0,5), (0,6), (1,5) and (1,6)
			groups = plpy.execute(
				"""SELECT array_agg(DISTINCT {gsql}) AS gsql
				FROM {edge_table} """.format(**locals()))[0]['gsql']

			# For each group initialize the output table
			for i in range(0,len(groups)):
				gslist = []
				gi = groups[i]

				gvals = _string_to_array(gi)

				# Prepare the sql check for a particular group
				# Example: gcomp will be "g1 = 0 AND g2 = 5"
				for j in range(0,len(glist)):
					gslist.append(glist[j] + " = " + gvals[j])
				gcomp = " AND ".join(gslist)

				# Find the vertices that are involved in this group
				plpy.execute(
					""" INSERT INTO {out_table}
					SELECT DISTINCT ON ({vertex_id})
						{grp_comma} {vertex_id} AS {vertex_id},
						CAST('Infinity' AS DOUBLE PRECISION) AS {weight},
					NULL::INT AS parent
					FROM (
						SELECT {src} AS {vertex_id} {comma_grp}
						FROM {edge_table} WHERE {gcomp}
						UNION
						SELECT {dest} AS {vertex_id} {comma_grp}
						FROM {edge_table} WHERE {gcomp}
						) x
					WHERE {vertex_id} IS NOT NULL
					""".format(**locals()))

				# The source can be reached with 0 cost and
				# it has itself as the parent.
				plpy.execute(
					""" INSERT INTO {oldupdate}
						VALUES({source_vertex},0,{source_vertex},{gi})
					""".format(**locals()))

			# The maximum number of vertices for any group.
			# Used for determining negative cycles.
			v_cnt = plpy.execute(
				""" SELECT max(count) as max FROM (
						SELECT count({vertex_id}) AS count
						FROM {out_table}
						GROUP BY {grouping_cols}) x
				""".format(**locals()))[0]['max']
		else:

			plpy.execute(
				""" INSERT INTO {out_table}
				SELECT {vertex_id} AS {vertex_id},
					CAST('Infinity' AS DOUBLE PRECISION) AS {weight},
					NULL AS parent
				FROM {vertex_table}
				WHERE {vertex_id} IS NOT NULL
				 """.format(**locals()))

			# The source can be reached with 0 cost and it has itself as the parent.
			plpy.execute(
				""" INSERT INTO {oldupdate}
					VALUES({source_vertex},0,{source_vertex})
				""".format(**locals()))

			v_cnt = plpy.execute(
				""" SELECT count(*) FROM {vertex_table}
				WHERE {vertex_id} IS NOT NULL
				""".format(**locals()))[0]['count']

		for i in range(0,v_cnt+1):

			# Apply the updates calculated in the last iteration
			if is_hawq:
				sql = """
				TRUNCATE TABLE {temp_table};
				INSERT INTO {temp_table}
					SELECT *
					FROM {out_table}
					WHERE NOT EXISTS (
						SELECT 1
						FROM {oldupdate} as oldupdate
						WHERE {out_table}.{vertex_id} = oldupdate.id
						{checkg_oo})
					UNION
					SELECT {grp_comma} id, {weight}, parent FROM {oldupdate};
				DROP TABLE {out_table};
				ALTER TABLE {temp_table} RENAME TO {out_table};
				CREATE TABLE {temp_table} AS (
					SELECT * FROM {out_table} LIMIT 0)
					{distribution};"""
				plpy.execute(sql.format(**locals()))
				ret = plpy.execute("SELECT 1 AS one FROM {0} LIMIT 1".
					format(out_table))
			else:
				sql = """
				UPDATE {out_table} SET
				{weight}=oldupdate.{weight},
				parent=oldupdate.parent
				FROM
				{oldupdate} AS oldupdate
				WHERE
				{out_table}.{vertex_id}=oldupdate.id AND
				{out_table}.{weight}>oldupdate.{weight} {checkg_oo}
				"""
				ret = plpy.execute(sql.format(**locals()))

			if ret.nrows() == 0:
				break
			plpy.info(plpy.execute("SELECT * FROM {0}".format(out_table)))
			plpy.execute("TRUNCATE TABLE {0}".format(newupdate))

			# 'oldupdate' table has the update info from the last iteration

			# Consider every edge that has an updated source
			# From these edges:
			# For every destination vertex, find the min total cost to reach.
			# Note that, just calling an aggregate function with group by won't
			# let us store the src field of the edge (needed for the parent).
			# This is why we need the 'x'; it gives a list of destinations and
			# associated min values. Using these values, we identify which edge
			# is selected.

			# Since using '='' with floats is dangerous we use an epsilon value
			# for comparison.

			# Once we have a list of edges and values (stores as 'message'),
			# we check if these values are lower than the existing shortest path
			# values.

			sql = (""" INSERT INTO {newupdate}
				SELECT DISTINCT ON (message.id {comma_grp})
					message.id AS id,
					message.{weight} AS {weight},
					message.parent AS parent {comma_grp_m}
				FROM {out_table} AS out_table INNER JOIN
					(
					SELECT {edge_table}.{dest} AS id, x.{weight} AS {weight},
						oldupdate.id AS parent {comma_grp_e}
					FROM {oldupdate} AS oldupdate INNER JOIN
						{edge_table}  ON
							({edge_table}.{src} = oldupdate.id {checkg_eo})
						INNER JOIN
						(
						SELECT {edge_table}.{dest} AS id,
							min(oldupdate.{weight} +
								{edge_table}.{weight}) AS {weight} {comma_grp_e}
						FROM {oldupdate} AS oldupdate INNER JOIN
							{edge_table}  ON
							({edge_table}.{src}=oldupdate.id {checkg_eo})
						GROUP BY {edge_table}.{dest} {comma_grp_e}
						) x
						ON ({edge_table}.{dest} = x.id {checkg_ex} )
					WHERE ABS(oldupdate.{weight} + {edge_table}.{weight}
								- x.{weight}) < {EPSILON}
					) message
					ON (message.id = out_table.{vertex_id} {checkg_om})
				WHERE message.{weight}<out_table.{weight}
				""".format(**locals()))

			plpy.execute(sql)

			# Swap the update tables for the next iteration
			tmp = oldupdate
			oldupdate = newupdate
			newupdate = tmp

		# The algorithm should converge in less than |V| iterations.
		# Otherwise there is a negative cycle in the graph.
		if i == v_cnt:
			if grouping_cols is None:
				plpy.execute("DROP TABLE IF EXISTS {out_table}".
					format(**locals()))
				plpy.error("Graph SSSP: Detected a negative cycle in the graph.")

			# It is possible that not all groups has negative cycles
			else:

				# gsql is the string created by collating grouping columns.
				# By looking at the oldupdate table we can see which groups
				# are in a negative cycle.

				negs = plpy.execute(
					""" SELECT array_agg(DISTINCT {gsql}) AS grp
						FROM {oldupdate}
					""".format(**locals()))[0]['grp']

				# Delete the groups with negative cycles from the output table
				sql_del = m4_ifdef(<!__HAWQ__!>,
				<!"""
				TRUNCATE TABLE {temp_table};
				INSERT INTO {temp_table}
					SELECT *
					FROM {out_table}
					WHERE NOT EXISTS(
						SELECT 1
						FROM {oldupdate} as oldupdate
						WHERE {checkg_oo_sub}
						)
				DROP TABLE {out_table};
				ALTER TABLE {temp_table} RENAME TO {out_table};
				"""!>,
				<!"""
				DELETE FROM {out_table} USING {oldupdate} AS oldupdate
				WHERE {checkg_oo_sub}
				"""!>)
				plpy.execute(sql_del.format(**locals()))

				# If every group has a negative cycle,
				# drop the output table as well
				if table_is_empty(out_table):
					plpy.execute("DROP TABLE IF EXISTS {0}".format(out_table))

				plpy.warning(
					"""Graph SSSP: Detected a negative cycle in the """ +
					"""sub-graphs of following groups: {0}.""".
					format(str(negs)[1:-1]))

		if is_hawq:
			plpy.execute("DROP TABLE IF EXISTS {temp_table} ".
				format(**locals()))

	return None

def graph_sssp_old(schema_madlib, vertex_table, vertex_id, edge_table,
		edge_args, source_vertex, out_table, grouping_cols, **kwargs):
	"""
    Single source shortest path function for graphs using the Bellman-Ford
    algorhtm [1].
    Args:
        @param vertex_table     Name of the table that contains the vertex data.
        @param vertex_id        Name of the column containing the vertex ids.
        @param edge_table       Name of the table that contains the edge data.
        @param edge_args        A comma-delimited string containing multiple
        						named arguments of the form "name=value".
        @param source_vertex    The source vertex id for the algorithm to start.
        @param out_table   	    Name of the table to store the result of SSSP.

    [1] https://en.wikipedia.org/wiki/Bellman-Ford_algorithm
    """

	graph_sssp2(schema_madlib, vertex_table, vertex_id, edge_table,
		edge_args, source_vertex, out_table, grouping_cols)
	return
	with MinWarning("warning"):

		INT_MAX = 2147483647
		EPSILON = 0.000001

		message = unique_string(desp='message')

		oldupdate = unique_string(desp='oldupdate')
		newupdate = unique_string(desp='newupdate')

		params_types = {'src': str, 'dest': str, 'weight': str}
		default_args = {'src': 'src', 'dest': 'dest', 'weight': 'weight'}
		edge_params = extract_keyvalue_params(edge_args,
                                            params_types,
                                            default_args)
		if vertex_id is None:
			vertex_id = "id"

		src = edge_params["src"]
		dest = edge_params["dest"]
		weight = edge_params["weight"]

		distribution = m4_ifdef(<!__POSTGRESQL__!>, <!''!>,
			<!"DISTRIBUTED BY ({0})".format(vertex_id)!>)
		local_distribution = m4_ifdef(<!__POSTGRESQL__!>, <!''!>,
			<!"DISTRIBUTED BY (id)"!>)

		validate_sssp(vertex_table, vertex_id, edge_table,
			edge_params, source_vertex, out_table)

		plpy.execute(" DROP TABLE IF EXISTS {0},{1},{2}".format(
			message,oldupdate,newupdate))

		# We keep a table of every vertex, the minimum cost to that destination
		# seen so far and the parent to this vertex in the associated shortest
		# path. This table will be updated throughtout the execution.
		plpy.execute(
			""" CREATE TABLE {out_table} AS
				SELECT {vertex_id} AS {vertex_id},
					CAST('Infinity' AS DOUBLE PRECISION) AS {weight},
					NULL::INT AS parent
				FROM {vertex_table}
				WHERE {vertex_id} IS NOT NULL
				{distribution} """.format(**locals()))

		# We keep 2 update tables and alternate them during the execution.
		# This is necessary since we need to know which vertices are updated in
		# the previous iteration to calculate the next set of updates.
		plpy.execute(
			""" CREATE TEMP TABLE {oldupdate}(
				id INT, {weight} DOUBLE PRECISION, parent INT)
				{local_distribution}
				""".format(**locals()))
		plpy.execute(
			""" CREATE TEMP TABLE {newupdate}(
				id INT, {weight} DOUBLE PRECISION, parent INT)
				{local_distribution}
				""".format(**locals()))

		# Since HAWQ does not allow us to update, we create a new table and
		# rename at every iteration
		temp_table = unique_string(desp='temp')
		sql = m4_ifdef(<!__HAWQ__!>,
			""" CREATE TABLE {temp_table} (
					{vertex_id} INT, {weight} DOUBLE PRECISION, parent INT)
					{distribution};
			""",  <!''!>)
		plpy.execute(sql.format(**locals()))

		# GPDB and HAWQ have distributed by clauses to help them with indexing.
		# For Postgres we add the indices manually.
		sql_index = m4_ifdef(<!__POSTGRESQL__!>,
			<!""" CREATE INDEX ON {out_table} ({vertex_id});
				CREATE INDEX ON {oldupdate} (id);
				CREATE INDEX ON {newupdate} (id);
			""".format(**locals())!>,
			<!''!>)
		plpy.execute(sql_index)

		# The source can be reached with 0 cost and it has itself as the parent.
		plpy.execute(
			""" INSERT INTO {oldupdate}
				VALUES({source_vertex},0,{source_vertex})
			""".format(**locals()))

		v_cnt = plpy.execute(
			"""SELECT count(*) FROM {vertex_table}
			WHERE {vertex_id} IS NOT NULL""".format(**locals()))[0]['count']
		for i in range(0,v_cnt+1):

			# plpy.info(i)
			# if i == 3:
			# 	break
			# Apply the updates calculated in the last iteration
			sql = m4_ifdef(<!__HAWQ__!>,
				<!"""
				TRUNCATE TABLE {temp_table};
				INSERT INTO {temp_table}
					SELECT *
					FROM {out_table}
					WHERE {out_table}.{vertex_id} NOT IN (
						SELECT {oldupdate}.id FROM {oldupdate})
					UNION
					SELECT * FROM {oldupdate};
				DROP TABLE {out_table};
				ALTER TABLE {temp_table} RENAME TO {out_table};
				CREATE TABLE {temp_table} (
					{vertex_id} INT, {weight} DOUBLE PRECISION, parent INT)
					{distribution};
				"""!>,
				<!"""
				UPDATE {out_table} SET
				{weight}=oldupdate.{weight},
				parent=oldupdate.parent
				FROM
				{oldupdate} AS oldupdate
				WHERE
				{out_table}.{vertex_id}=oldupdate.id
				"""!>)
			plpy.execute(sql.format(**locals()))

			plpy.execute("TRUNCATE TABLE {0}".format(newupdate))

			# 'oldupdate' table has the update info from the last iteration

			# Consider every edge that has an updated source
			# From these edges:
			# For every destination vertex, find the min total cost to reach.
			# Note that, just calling an aggregate function with group by won't
			# let us store the src field of the edge (needed for the parent).
			# This is why we need the 'x'; it gives a list of destinations and
			# associated min values. Using these values, we identify which edge
			# is selected.

			# Since using '='' with floats is dangerous we use an epsilon value
			# for comparison.

			# Once we have a list of edges and values (stores as 'message'),
			# we check if these values are lower than the existing shortest path
			# values.

			sql = (""" INSERT INTO {newupdate}
				SELECT DISTINCT ON (message.id) message.id AS id,
					message.{weight} AS {weight},
					message.parent AS parent
				FROM {out_table} AS out_table INNER JOIN
					(
						SELECT edge_table.{dest} AS id, x.{weight} AS {weight},
							oldupdate.id AS parent
						FROM {oldupdate} AS oldupdate INNER JOIN
							{edge_table} AS edge_table ON
							(edge_table.{src} = oldupdate.id) INNER JOIN
							(
							SELECT edge_table.{dest} AS id,
								min(oldupdate.{weight} + edge_table.{weight})
								AS {weight}
							FROM {oldupdate} AS oldupdate INNER JOIN
								{edge_table} AS edge_table ON
								(edge_table.{src}=oldupdate.id)
							GROUP BY edge_table.{dest}
							) x ON (edge_table.{dest} = x.id)
						WHERE ABS(oldupdate.{weight} + edge_table.{weight} - x.{weight})
							< {EPSILON}
					) AS message ON (message.id = out_table.{vertex_id})
				WHERE message.{weight}<out_table.{weight}
				""".format(**locals()))

			# If there are no updates, SSSP is finalized
			ret = plpy.execute(sql)
			if ret.nrows() == 0:
				break

			# Swap the update tables for the next iteration
			tmp = oldupdate
			oldupdate = newupdate
			newupdate = tmp

		# Bellman-Ford should converge in |V|-1 iterations.
		if i == v_cnt:
			plpy.execute("DROP TABLE IF EXISTS {out_table}".format(**locals()))
			plpy.error("Graph SSSP: Detected a negative cycle in the graph.")

		m4_ifdef(<!__HAWQ__!>,
			plpy.execute("DROP TABLE {temp_table} ".format(**locals())), <!''!>)

	return None


def _path_helper(plan_name, dest_vertex, path_table, gset):

	ret = [str(dest_vertex)]
	cur = dest_vertex
	sql = "EXECUTE {plan_name} ({cur})"
	parent = plpy.execute(sql.format(**locals()))
	if parent.nrows() > 0:
		while 1:
			parent = parent[0]['parent']
			if parent == cur:
				ret.reverse()
				ret = ",".join(ret)
				plpy.execute(
					""" INSERT INTO {path_table} VALUES ({gset} '{ret}')
					""".format(**locals()))
				return True
			else:
				ret.append(str(parent))
				cur = parent

			parent = plpy.execute(sql.format(**locals()))

	return False

def graph_sssp_get_path(schema_madlib, sssp_table, dest_vertex, path_table, grouping_cols, **kwargs):
	"""
	Helper function that can be used to get the shortest path for a vertex
    Args:
    	@param source_table	Name of the table that contains the SSSP output.
        @param out_table	The vertex that will be the destination of the
            				desired path.
	"""
	with MinWarning("warning"):

		validate_get_path(sssp_table, dest_vertex)
		plan_name = unique_string(desp='plan')

		select_grps = ""
		gsql = ""

		path_flag = False

		summary = plpy.execute("SELECT * FROM {0}_summary".format(sssp_table))
		vertex_id = summary[0]['vertex_id']
		if vertex_id == "NULL":
			vertex_id = "id"

		grouping_cols = summary[0]['grouping_cols']
		if grouping_cols != "NULL":
			glist = split_quoted_delimited_str(grouping_cols)
			select_grps = _grp_from_table(sssp_table,glist) + " , "

		plpy.execute("""
			CREATE TABLE {path_table} AS
				SELECT {select_grps} ''::text as path
				FROM {sssp_table}
				LIMIT 0
			""".format(**locals()))

		plan = """ PREPARE {plan_name} (int) AS
			SELECT parent FROM {sssp_table}
			WHERE {vertex_id} = $1 AND parent IS NOT NULL {gsql} LIMIT 1
			"""

		if grouping_cols == "NULL":
			plpy.execute(plan.format(**locals()))
			plpy.info(plan.format(**locals()))
			path_flag = _path_helper(plan_name,dest_vertex,path_table,"")
			plpy.info("here " + str(path_flag))

		else:
			gvalues = plpy.execute(
				""" SELECT {grouping_cols} FROM {sssp_table}
					GROUP BY {grouping_cols}""".format(**locals()))

			for i in gvalues:
				cur = dest_vertex
				gcheck = []
				gset = []
				for j in glist:
					gcheck.append("{0} = {1}".format(j,i[j]))
					gset.append("{0}".format(i[j]))
				gsql = " AND " + " AND ".join(gcheck)
				gset = " , ".join(gset) + " , "

				# Follow the 'parent' chain until you reach the source.
				# We don't need to know what the source is since it is the
				# only vertex with itself as its parent
				plpy.execute(plan.format(**locals()))
				path_flag = path_flag | _path_helper(
					plan_name,dest_vertex,path_table,gset)

				plpy.execute("DEALLOCATE {0}".format(plan_name))

		if path_flag is False:
			plpy.execute("DROP TABLE IF EXISTS {0}".format(path_table))
			plpy.error(
				"Graph SSSP: Vertex {0} is not present in the sssp table {1}".
				format(dest_vertex,sssp_table))

	return None

def graph_sssp_get_path_old(schema_madlib, sssp_table, dest_vertex, **kwargs):
	"""
	Helper function that can be used to get the shortest path for a vertex
    Args:
    	@param source_table	Name of the table that contains the SSSP output.
        @param out_table	The vertex that will be the destination of the
            				desired path.
	"""

	validate_get_path(sssp_table, dest_vertex)
	cur = dest_vertex
	cols = get_cols(sssp_table)
	id = cols[0]
	ret = [dest_vertex]
	plan_name = unique_string(desp='plan')

	# Follow the 'parent' chain until you reach the source.
	# We don't need to know what the source is since it is the only vertex with
	# itself as its parent
	plpy.execute(""" PREPARE {plan_name} (int) AS
		SELECT parent FROM {sssp_table} WHERE {id} = $1 LIMIT 1
		""".format(**locals()))
	sql = "EXECUTE {plan_name} ({cur})"
	parent = plpy.execute(sql.format(**locals()))

	if parent.nrows() == 0:
		plpy.error(
			"Graph SSSP: Vertex {0} is not present in the sssp table {1}".
			format(dest_vertex,sssp_table))

	while 1:
		parent = parent[0]['parent']
		if parent == cur:
			ret.reverse()
			return ret
		else:
			ret.append(parent)
			cur = parent
		parent = plpy.execute(sql.format(**locals()))

	return None

def validate_sssp(vertex_table, vertex_id, edge_table, edge_params,
	source_vertex, out_table, **kwargs):

	validate_graph_coding(vertex_table, vertex_id, edge_table, edge_params,
		out_table,'SSSP')

	_assert(isinstance(source_vertex,int),
		"""Graph SSSP: Source vertex {source_vertex} has to be an integer """.
		format(**locals()))
	src_exists = plpy.execute("""
		SELECT * FROM {vertex_table} WHERE {vertex_id}={source_vertex}
		""".format(**locals()))

	if src_exists.nrows() == 0:
		plpy.error(
			"""Graph SSSP: Source vertex {source_vertex} is not present in the
			vertex table {vertex_table} """.format(**locals()))

	vt_error = plpy.execute(
		""" SELECT {vertex_id}
			FROM {vertex_table}
			WHERE {vertex_id} IS NOT NULL
			GROUP BY {vertex_id}
			HAVING count(*) > 1 """.format(**locals()))

	if vt_error.nrows() != 0:
		plpy.error(
			"""Graph SSSP: Source vertex table {vertex_table}
			contains duplicate vertex id's """.format(**locals()))

	return None

def validate_get_path(sssp_table, dest_vertex, **kwargs):

	_assert(sssp_table and sssp_table.strip().lower() not in ('null', ''),
		"Graph SSSP: Invalid SSSP table name!")
	_assert(table_exists(sssp_table),
		"Graph SSSP: SSSP table ({0}) is missing!".format(sssp_table))
	_assert(not table_is_empty(sssp_table),
		"Graph SSSP: SSSP table ({0}) is empty!".format(sssp_table))

	summary = sssp_table+"_summary"
	_assert(table_exists(summary),
		"Graph SSSP: SSSP summary table ({0}) is missing!".format(summary))
	_assert(not table_is_empty(summary),
		"Graph SSSP: SSSP summary table ({0}) is empty!".format(summary))


def graph_sssp_help(schema_madlib, message, **kwargs):
    """
    Help function for graph_sssp and graph_sssp_get_path

    Args:
        @param schema_madlib
        @param message: string, Help message string
        @param kwargs

    Returns:
        String. Help/usage information
    """
    if not message:
        help_string = """
-----------------------------------------------------------------------
                            SUMMARY
-----------------------------------------------------------------------

Given a graph and a source vertex, single source shortest path (SSSP)
algorithm finds a path for every vertex such that the the sum of the
weights of its constituent edges is minimized.

For more details on function usage:
    SELECT {schema_madlib}.graph_sssp('usage')
            """
    elif message in ['usage', 'help', '?']:
        help_string = """
{graph_usage}

To retrieve the path for a specific vertex:

 SELECT {schema_madlib}.graph_sssp_get_path(
    sssp_table	TEXT, -- Name of the table that contains the SSSP output.
    dest_vertex	INT   -- The vertex that will be the destination of the
    		  -- desired path.
);

----------------------------------------------------------------------------
                            OUTPUT
----------------------------------------------------------------------------
The output table ('out_table' above) will contain a row for every vertex from
vertex_table and have the following columns:

vertex_id 	: The id for the destination. Will use the input parameter
		(vertex_id) for column naming.
weight 		: The total weight of the shortest path from the source vertex
		to this particular vertex. Will use the input parameter (weight)
		for column naming.
parent 		: The parent of this vertex in the shortest path from source.
		Will use "parent" for column naming.

The graph_sssp_get_path function will return an INT array that contains the
shortest path from the initial source vertex to the desired destination vertex.
"""
    else:
        help_string = "No such option. Use {schema_madlib}.graph_sssp()"

    return help_string.format(schema_madlib=schema_madlib,
    	graph_usage=get_graph_usage(schema_madlib, 'graph_sssp',
    """source_vertex INT,  -- The source vertex id for the algorithm to start.
    out_table     TEXT  -- Name of the table to store the result of SSSP."""))
# ---------------------------------------------------------------------

